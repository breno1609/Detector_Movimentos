{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e32cdc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00f89a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_SOURCE = 'Cars.mp4' #VAI GUARDAR O CAMINHO DO ARQUIVO\n",
    "VIDEO_OUT = 'filtragem_mediana_temporal.avi' #ONDE OS RESULTADOS VAI FICAR ARMAZENADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d46eca75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True (720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "#REALIZANDO A LEITURA DO VIDEO\n",
    "cap = cv2.VideoCapture(VIDEO_SOURCE)\n",
    "hasframe, frame = cap.read() #HASFRAME VAI INFROMAR SE FOI POSSIVEL FAZER A LEITUR DO VIDEO E FRAME VAI FAZER A LEITURA DO PRIMEIRO FRAME\n",
    "print(hasframe, frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd07a658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000.0\n"
     ]
    }
   ],
   "source": [
    "#VAI GRAVAR O VIDEO DE RESULTADO\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') #VIDEPWRITE = CODEC PARA GRAVAR O VIDEO XVIDE É A EXTENSÃO\n",
    "writer = cv2.VideoWriter(VIDEO_OUT, fourcc, 25,\n",
    "                         (frame.shape[1], \n",
    "                          frame.shape[0]), False) #GRAVAR O VIDEO, PASSA COMO PARAMETRO ONDE VAI SALVAR O VIDEO, 25 é  a quantidade de frames\n",
    "\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_COUNT))  #CONTAR A QUANTIDADE DE FRAMES NO VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3319fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1266.25506717 2613.78135291  261.3597094  2518.83162899  982.3102073\n",
      " 1140.70002555 2873.24445567 2235.30546933 1551.80640314 1419.67960762\n",
      " 2035.97782962  454.67596712   61.77391732  361.92505946 1825.38897414\n",
      "   10.43090324 2555.7323137   600.14308082 1496.54195431 2450.39053125\n",
      "  581.21357835 1826.5413122  2920.68056679 2097.06767473 1296.91322091]\n"
     ]
    }
   ],
   "source": [
    "#EXTRAINDO 25 FRAMES ALEATORIOS DO VIDEO, PARA FAZER A SUBTRAÇÃO DO FUNDO\n",
    "framesid = cap.get(cv2.CAP_PROP_FRAME_COUNT) *np.random.uniform(size=25)\n",
    "print(framesid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74f7d3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ACESSAR UM FRAME ESPECIFICO E FAZER A LEITURA DELE\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 194)\n",
    "hasframe, frame = cap.read() #VAI INFORMAR SE FOI POSSIVEL LER O VIDEO E FAZER A LEITURA DO FRAME ESPECIFICO\n",
    "cv2.imshow('Teste', frame)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b0a203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 720, 1280, 3)\n",
      "[[[242 232 218]\n",
      "  [242 232 218]\n",
      "  [242 232 218]\n",
      "  ...\n",
      "  [ 92 149 147]\n",
      "  [ 98 155 153]\n",
      "  [100 157 155]]\n",
      "\n",
      " [[242 232 218]\n",
      "  [242 232 218]\n",
      "  [242 232 218]\n",
      "  ...\n",
      "  [102 159 157]\n",
      "  [ 93 150 148]\n",
      "  [ 74 131 129]]\n",
      "\n",
      " [[242 232 218]\n",
      "  [242 232 218]\n",
      "  [242 232 218]\n",
      "  ...\n",
      "  [ 87 137 136]\n",
      "  [ 87 135 134]\n",
      "  [ 76 124 123]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 75  82  95]\n",
      "  [ 75  82  95]\n",
      "  [ 71  83  93]\n",
      "  ...\n",
      "  [168 143 141]\n",
      "  [168 143 141]\n",
      "  [167 142 140]]\n",
      "\n",
      " [[ 71  83  95]\n",
      "  [ 71  83  95]\n",
      "  [ 70  85  94]\n",
      "  ...\n",
      "  [163 142 141]\n",
      "  [163 142 141]\n",
      "  [163 142 141]]\n",
      "\n",
      " [[ 68  80  92]\n",
      "  [ 70  82  94]\n",
      "  [ 68  83  92]\n",
      "  ...\n",
      "  [163 142 141]\n",
      "  [163 142 141]\n",
      "  [163 142 141]]]\n"
     ]
    }
   ],
   "source": [
    "#ARMAZENAR TODOS OS FRAMES EM UMA MATRIZ\n",
    "frames = []\n",
    "for fid in framesid:\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, fid)\n",
    "    hasframe, frame = cap.read()\n",
    "    frames.append(frame)\n",
    "    \n",
    "print(np.asarray(frames).shape)\n",
    "print(frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "687b81d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FAZENDO A LEITURA DOS FRAMES\n",
    "for frame in frames:\n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b0c9bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[242 234 220]\n",
      "  [242 234 220]\n",
      "  [242 234 220]\n",
      "  ...\n",
      "  [ 89 143 143]\n",
      "  [ 91 149 145]\n",
      "  [ 96 152 149]]\n",
      "\n",
      " [[242 234 220]\n",
      "  [242 234 220]\n",
      "  [242 234 220]\n",
      "  ...\n",
      "  [ 91 144 143]\n",
      "  [ 81 137 135]\n",
      "  [ 70 125 123]]\n",
      "\n",
      " [[242 234 220]\n",
      "  [242 234 220]\n",
      "  [242 234 220]\n",
      "  ...\n",
      "  [ 81 128 128]\n",
      "  [ 81 127 127]\n",
      "  [ 73 121 121]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 70  80  92]\n",
      "  [ 70  80  92]\n",
      "  [ 70  82  92]\n",
      "  ...\n",
      "  [ 96  92  95]\n",
      "  [ 96  92  95]\n",
      "  [ 96  92  96]]\n",
      "\n",
      " [[ 70  80  92]\n",
      "  [ 71  80  92]\n",
      "  [ 72  84  94]\n",
      "  ...\n",
      "  [ 96  93  96]\n",
      "  [ 96  93  96]\n",
      "  [ 96  93  96]]\n",
      "\n",
      " [[ 69  79  92]\n",
      "  [ 70  79  91]\n",
      "  [ 68  81  91]\n",
      "  ...\n",
      "  [ 96  93  96]\n",
      "  [ 97  93  97]\n",
      "  [ 97  94  97]]]\n"
     ]
    }
   ],
   "source": [
    "#CALCULAR A MEDIAnA, PARA GERAR O BACKGROUD(FUNDO DA IMAGEM)\n",
    "medianframe = np.median(frames, axis=0).astype(dtype=np.uint8)\n",
    "print(medianframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fe40055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMAGEM DO FUNDO PURO\n",
    "cv2.imshow('Median Frame', medianframe)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "492afd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SALVANDO A IMAGEM MEDIA(IMAGEM DE FUNDO VAZIO)\n",
    "cv2.imwrite('model_median_frame.jpg', medianframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be0c07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 PASSO: CONVERTER A IMAGEM MEDIAN PARA CINZA\n",
    "#COMPARAR OS FRAMES COM O FRAME MEDIO\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "grayMediaFrame = cv2.cvtColor(medianframe, cv2.COLOR_BGR2GRAY) #CONVERTENDO A IMAGEM MEDIAN PARA CINZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3227b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 PASSO: FAZER UM LOOP PARA RODAR O VIDE(FAZER A LEITURA DE FRAME A FRAME)\n",
    "#LOOP PARA RODAR O FRAME (FAZENDO A LEITURA FRAME A FRAME)\n",
    "while (True):\n",
    "    hasframe, frame = cap.read()\n",
    "    \n",
    "    if not hasframe:\n",
    "        print('ERRO')\n",
    "        break\n",
    "        \n",
    "    framegray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #3 PASSO: CALCULAR A DIFERENÇA ABSOLUTA ENTRE O FRAME ATUAL E O MODELO DE FUNDO\n",
    "    dframe = cv2.absdiff(framegray, grayMediaFrame) #ABSDIFF CALCULA A DIFEREÇA\n",
    "    \n",
    "    #PASSO 4:\n",
    "    th, dframe = cv2.threshold(dframe, 70, 255,\n",
    "                               cv2.THRESH_BINARY) #IMGENS PRETA OU BRANCA , SE O PIXEL FROR >= 70 ELE VAI FICAR COM A COR PRETA E AJUDA  A ELIMINAR RUIDOS\n",
    "    \n",
    "    cv2.imshow('FRAME', dframe)\n",
    "    \n",
    "    writer.write(dframe)\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "writer.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b099e8e",
   "metadata": {},
   "source": [
    "###IMPLEMENTAÇÃO MOG, GMC, KNN E CNT ; PRÉ-PROCESSAMENTO DE IMAGENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01697c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcf42236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINIR PADRÕES DOS RESULTADOS\n",
    "#VAI SER GERADO TRES CORES\n",
    "TEXT_COLOR = (randint(0, 255), \n",
    "              randint(0, 255), \n",
    "              randint(0, 255))\n",
    "\n",
    "BORDER_COLOR = (randint(0, 255), \n",
    "                randint(0, 255),\n",
    "                randint(0, 255))\n",
    "\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "VIDEO_SOURCE = 'Traffic_4.mp4'\n",
    "\n",
    "#TIPOS DOS ALGORITIMOS PARA EXTRAÇÃO DE DADOS\n",
    "BGS_TYPES = ['GMG',\n",
    "             'MOG2',\n",
    "             'MOG',\n",
    "             'KNN',\n",
    "             'CNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc182000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [1 1 1]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "#FUNÇÃO QUE VAI CALCURLAR E RETORNAR O TIPO DE MATRIZ\n",
    "\n",
    "def getKernel(KERNEL_TYPE):\n",
    "    if KERNEL_TYPE == 'dilation': #AUMENTA O TAMANHO DA IMAGEM\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, \n",
    "                                           (3, 3))\n",
    "    if KERNEL_TYPE == 'opening':\n",
    "        kernel = np.ones((3, 3), \n",
    "                         np.uint8)\n",
    "    if KERNEL_TYPE == 'closing':\n",
    "        kernel = np.ones((3, 3),\n",
    "                         np.uint8)\n",
    "    return kernel\n",
    "print(getKernel('dilation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36822d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNÇÃO PARA ESCOLHER OS FILTROS\n",
    "def getFilter(img, filter):\n",
    "    if filter == 'closing':\n",
    "        return cv2.morphologyEx(img, \n",
    "                                cv2.MORPH_CLOSE, \n",
    "                                getKernel('closing'), \n",
    "                                interations=2)\n",
    "    if filter == 'opening':\n",
    "        return cv2.morphologyEx(img, \n",
    "                                cv2.MORPH_OPEN, \n",
    "                                getKernel('opening'), \n",
    "                                interations=2)\n",
    "    if filter == 'dilation':\n",
    "        return cv2.dilate(img, \n",
    "                          getKernel('dilation'), \n",
    "                          interations=2)\n",
    "    #PRECISA TESTAR AS COMBINAÇÕES, VOCÊ TESTA A COMBINAÇÃO QUE MELHOR SATISFAZ\n",
    "    if filter == 'combine':\n",
    "        closing = cv2.morphologyEx(img, \n",
    "                                   cv2.MORPH_CLOSE, \n",
    "                                   getKernel('closing'), \n",
    "                                   interations=2)\n",
    "        \n",
    "        closing = cv2.morphologyEx(closing, \n",
    "                                   cv2.MORPH_OPEN, \n",
    "                                   getKernel('opening'), \n",
    "                                   interations=2)\n",
    "        \n",
    "        dilation = cv2.dilation(opening, \n",
    "                                getKernel('dilation'), \n",
    "                                interations=2)\n",
    "        return dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "609919a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8485f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBGSubtractor(BGS_TYPE):\n",
    "    if BGS_TYPE == 'GMG':\n",
    "        return cv2.bgsegm.createBackgroundSubtractorGMG(initializationFrames=120, \n",
    "                                                        decisionThreshold=0.8)\n",
    "    if BGS_TYPE == 'MOG':\n",
    "        return cv2.bgsegm.createBackgroundSubtractorMOG(history=200, #COMPRIMENTO DA HISTORIA, NUMERO DE FRAMES QUE USARA PARA CARREGAR OS PESOS(NUMERO DE FRAMES QUE SERÁ USADO)\n",
    "                                                        nmixtures=5, #NUMERO DE MISTURAS GAUSIANAS, VALORES ALTOS ALTERAM O TEMPO\n",
    "                                                        backgroundRatio=0.7, #DEFINE O QUE O PRIMERIO E SEGUNDO PLANO\n",
    "                                                        noiseSigma=0) #NUMERO DE RUIDOS ACEITOS\n",
    "    if BGS_TYPE == 'MOG2':\n",
    "        return cv2.createBackgroundSubtractorMOG2(history=500, \n",
    "                                           detectShadows=True, \n",
    "                                           varThreshold=100)\n",
    "    if BGS_TYPE == 'KNN':\n",
    "        return cv2.createBackgroundSubtractorKNN(history=400, \n",
    "                                          dist2Threshold=400, \n",
    "                                          detectShadows=True)\n",
    "    if BGS_TYPE == 'CNT':\n",
    "        return cv2.bgsegm.createBackgroundSubtractorCNT(minPixelStability=15, #SE APOS 15 FRAMES NAO TIVER MUDANÇA, É CONSIDEREADO PLANO DE FUNDO\n",
    "                                                 useHistory=True, \n",
    "                                                 maxPixelStability=15*60,\n",
    "                                                 isParallel=True)\n",
    "    print('DETECTOR INVÁLIDO')\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e366e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(VIDEO_SOURCE)\n",
    "#TESTANDO O GMG\n",
    "bg_subtractor = getBGSubtractor(BGS_TYPES[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d38ac6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'morphologyEx'\n> Overload resolution failed:\n>  - 'interations' is an invalid keyword argument for morphologyEx()\n>  - 'interations' is an invalid keyword argument for morphologyEx()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 36>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     35\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m bg_mask \u001b[38;5;241m=\u001b[39m bg_subtractor\u001b[38;5;241m.\u001b[39mapply(frame)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#fg_mask = getFilter(bg_mask, 'dilation')\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m fg_mask_closing \u001b[38;5;241m=\u001b[39m \u001b[43mgetFilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbg_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclosing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m fg_mask_opening \u001b[38;5;241m=\u001b[39m getFilter(bg_mask, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopening\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m fg_mask_combine \u001b[38;5;241m=\u001b[39m getFilter(bg_mask, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombine\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36mgetFilter\u001b[1;34m(img, filter)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetFilter\u001b[39m(img, \u001b[38;5;28mfilter\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclosing\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 4\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmorphologyEx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMORPH_CLOSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mgetKernel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclosing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                \u001b[49m\u001b[43minterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopening\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mmorphologyEx(img, \n\u001b[0;32m     10\u001b[0m                                 cv2\u001b[38;5;241m.\u001b[39mMORPH_OPEN, \n\u001b[0;32m     11\u001b[0m                                 getKernel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopening\u001b[39m\u001b[38;5;124m'\u001b[39m), \n\u001b[0;32m     12\u001b[0m                                 interations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'morphologyEx'\n> Overload resolution failed:\n>  - 'interations' is an invalid keyword argument for morphologyEx()\n>  - 'interations' is an invalid keyword argument for morphologyEx()\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    while cap.isOpened(): #VERIFICAR SE O VIDEO ESTA ABERTO\n",
    "        ok, frame = cap.read()\n",
    "        \n",
    "        frame = cv2.resize(frame, (0,0), \n",
    "                           fx=0.5,\n",
    "                           fy=0.5)\n",
    "        #print(frame.shape)\n",
    "        \n",
    "        bg_mask = bg_subtractor.apply(frame)\n",
    "        #fg_mask = getFilter(bg_mask, 'dilation')\n",
    "        fg_mask_closing = getFilter(bg_mask, 'closing')\n",
    "        fg_mask_opening = getFilter(bg_mask, 'opening')\n",
    "        fg_mask_combine = getFilter(bg_mask, 'combine')\n",
    "        \n",
    "        res = cv2.bitwise_and(frame, frame, mask=bg_mask)\n",
    "        res_closing = cv2.bitwise_and(frame, frame, mask=fg_mask_closing)\n",
    "        res_opening = cv2.bitwise_and(frame, frame, mask=fg_mask_opening)\n",
    "        res_combine = cv2.bitwise_and(frame, frame, mask=f g_mask_combine)\n",
    "        \n",
    "        \n",
    "        if not ok:\n",
    "            print('ERRO')\n",
    "            break\n",
    "        \n",
    "        #cv2.imshow('Frame', frame)\n",
    "        #cv2.imshow('Bg MASK', bg_mask)\n",
    "        #cv2.imshow('BG MASK filter', fg_mask)\n",
    "        cv2.imshow('Final', res)\n",
    "        cv2.imshow('Final Closing', res_closing)\n",
    "        cv2.imshow('Final Opening', res_opening)\n",
    "        cv2.imshow('Final Combine', res_combine)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "main()"
 
